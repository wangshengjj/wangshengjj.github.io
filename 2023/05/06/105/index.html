<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>【Linux存储系列教程】ceph-mimic集群部署 | WangShengJJのblog</title><meta name="author" content="网笙久久"><meta name="copyright" content="网笙久久"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="【Linux存储系列教程】ceph-mimic集群部署 上一期教程：ceph的架构和原理下一期教程：ceph存储的使用  一、实验准备1.规划主机 系统版本：Centos7.9IP：192.168.140.10 &#x3D;&#x3D;主机名：&#x3D;&#x3D;ceph-node1|ceph&#x3D;&#x3D;集群节点&#x3D;&#x3D;和ceph-deploy  &#x3D;&amp;#x">
<meta property="og:type" content="article">
<meta property="og:title" content="【Linux存储系列教程】ceph-mimic集群部署">
<meta property="og:url" content="https://blog.wangshengjj.work/2023/05/06/105/index.html">
<meta property="og:site_name" content="WangShengJJのblog">
<meta property="og:description" content="【Linux存储系列教程】ceph-mimic集群部署 上一期教程：ceph的架构和原理下一期教程：ceph存储的使用  一、实验准备1.规划主机 系统版本：Centos7.9IP：192.168.140.10 &#x3D;&#x3D;主机名：&#x3D;&#x3D;ceph-node1|ceph&#x3D;&#x3D;集群节点&#x3D;&#x3D;和ceph-deploy  &#x3D;&amp;#x">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.dmoe.cc/random.php">
<meta property="article:published_time" content="2023-05-06T11:45:46.496Z">
<meta property="article:modified_time" content="2023-05-06T12:59:12.516Z">
<meta property="article:author" content="网笙久久">
<meta property="article:tag" content="集群">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="分布式存储集群">
<meta property="article:tag" content="ceph">
<meta property="article:tag" content="服务器搭建">
<meta property="article:tag" content="linux搭建服务器">
<meta property="article:tag" content="ceph-deploy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.dmoe.cc/random.php"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.wangshengjj.work/2023/05/06/105/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【Linux存储系列教程】ceph-mimic集群部署',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-06 20:59:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script><meting-js server="netease" type="playlist" id="7386208265" lrc-type="0" volume="0.5" fixed="true" mini="true" order="random" loop="all" autoplay="true" preload="auto" list-folded="true"></meting-js><script src="https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><meta name="generator" content="Hexo 6.1.0"></head><body><link rel="stylesheet" href="/css/barber-shop.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/medias/loading.gif" data-original="https://www.wangshengjj.work/upload/2022/10/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">139</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">185</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">261</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 博客主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.wangshengjj.work/"><i class="fa-fw fa fa-rss"></i><span> 主博客</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://cloud.wangshengjj.work/"><i class="fa-fw fa fa-cloud"></i><span> 云盘</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://start.wangshengjj.work/"><i class="fa-fw fa fa-paper-plane"></i><span> 起始页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://space.bilibili.com/219606508/bangumi/"><i class="fa-fw fas fa-video"></i><span> 我的追番</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://home.wangshengjj.work/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://vme50.wangshengjj.work/"><i class="fa-fw fas fa-music"></i><span> V我50</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://www.dmoe.cc/random.php')"><nav id="nav"><span id="blog-info"><a href="/" title="WangShengJJのblog"><span class="site-name">WangShengJJのblog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 博客主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.wangshengjj.work/"><i class="fa-fw fa fa-rss"></i><span> 主博客</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://cloud.wangshengjj.work/"><i class="fa-fw fa fa-cloud"></i><span> 云盘</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://start.wangshengjj.work/"><i class="fa-fw fa fa-paper-plane"></i><span> 起始页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://space.bilibili.com/219606508/bangumi/"><i class="fa-fw fas fa-video"></i><span> 我的追番</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://home.wangshengjj.work/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://vme50.wangshengjj.work/"><i class="fa-fw fas fa-music"></i><span> V我50</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【Linux存储系列教程】ceph-mimic集群部署</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-06T11:45:46.496Z" title="发表于 2023-05-06 19:45:46">2023-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-06T12:59:12.516Z" title="更新于 2023-05-06 20:59:12">2023-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/">服务器搭建</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/">笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/">centos</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/linux%E6%95%99%E7%A8%8B/">linux教程</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/linux%E6%95%99%E7%A8%8B/linux%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/">linux基础服务</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/linux%E6%95%99%E7%A8%8B/linux%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/%E9%9B%86%E7%BE%A4/">集群</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/linux%E6%95%99%E7%A8%8B/linux%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/%E9%9B%86%E7%BE%A4/%E5%AD%98%E5%82%A8/">存储</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/%E7%AC%94%E8%AE%B0/centos/linux%E6%95%99%E7%A8%8B/linux%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/%E9%9B%86%E7%BE%A4/%E5%AD%98%E5%82%A8/ceph/">ceph</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>50分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【Linux存储系列教程】ceph-mimic集群部署"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="【Linux存储系列教程】ceph-mimic集群部署"><a href="#【Linux存储系列教程】ceph-mimic集群部署" class="headerlink" title="【Linux存储系列教程】ceph-mimic集群部署"></a>【Linux存储系列教程】ceph-mimic集群部署</h1><blockquote>
<p><strong>上一期教程：<a target="_blank" rel="noopener" href="https://www.wsjj.top/archives/104">ceph的架构和原理</a></strong><br><strong>下一期教程：<a target="_blank" rel="noopener" href="https://www.wsjj.top/archives/106">ceph存储的使用</a></strong></p>
</blockquote>
<h2 id="一、实验准备"><a href="#一、实验准备" class="headerlink" title="一、实验准备"></a>一、实验准备</h2><h3 id="1-规划主机"><a href="#1-规划主机" class="headerlink" title="1.规划主机"></a>1.规划主机</h3><blockquote>
<p><strong>系统版本：<code>Centos7.9</code></strong><br><strong><code>IP</code>：<code>192.168.140.10</code> &#x3D;&#x3D;主机名：&#x3D;&#x3D;<code>ceph-node1</code>|<code>ceph</code>&#x3D;&#x3D;集群节点&#x3D;&#x3D;和<code>ceph-deploy</code>  &#x3D;&#x3D;硬盘：&#x3D;&#x3D;<code>/dev/sdb</code></strong><br><strong><code>IP</code>：<code>192.168.140.11</code> &#x3D;&#x3D;主机名：&#x3D;&#x3D;<code>ceph-node2</code>|<code>ceph</code>&#x3D;&#x3D;集群节点&#x3D;&#x3D;和<code>ceph-deploy</code>  &#x3D;&#x3D;硬盘：&#x3D;&#x3D;<code>/dev/sdb</code></strong><br><strong><code>IP</code>：<code>192.168.140.12</code> &#x3D;&#x3D;主机名：&#x3D;&#x3D;<code>ceph-node3</code>|<code>ceph</code>&#x3D;&#x3D;集群节点&#x3D;&#x3D;和<code>ceph-deploy</code>  &#x3D;&#x3D;硬盘：&#x3D;&#x3D;<code>/dev/sdb</code></strong><br><strong><code>IP</code>：<code>192.168.140.13</code> &#x3D;&#x3D;主机名：&#x3D;&#x3D;<code>ceph-client</code>|&#x3D;&#x3D;业务服务器&#x3D;&#x3D;</strong></p>
</blockquote>
<ul>
<li>修改主机名使用<code>hostnamectl set-hostname 主机名</code></li>
</ul>
<h3 id="2-所有主机关闭防火墙和SElinux、配置时间同步-重要"><a href="#2-所有主机关闭防火墙和SElinux、配置时间同步-重要" class="headerlink" title="2.所有主机关闭防火墙和SElinux、配置时间同步(重要)"></a>2.所有主机关闭防火墙和SElinux、配置时间同步(重要)</h3><blockquote>
<p><strong>关闭<code>防火墙</code>和<code>SElinux</code>略</strong><br><strong>先安装<code>ntpdate</code>命令，使用<code>yum install -y ntpdate</code>安装</strong><br><strong>设置时间同步：<code>ntpdate 120.25.115.20</code></strong></p>
</blockquote>
<h4 id="设置同步时间计划任务"><a href="#设置同步时间计划任务" class="headerlink" title="设置同步时间计划任务"></a>设置同步时间计划任务</h4><blockquote>
<p><strong>关于计划任务教程：<a target="_blank" rel="noopener" href="https://www.wsjj.top/archives/57">https://www.wsjj.top/archives/57</a></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# crontab  -e
*&#x2F;30 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate 120.25.115.20 &amp;&gt; &#x2F;dev&#x2F;null

[root@ceph-node1 ~]# crontab  -l
*&#x2F;30 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate 120.25.115.20 &amp;&gt; &#x2F;dev&#x2F;null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-配置免密SSH-重要"><a href="#3-配置免密SSH-重要" class="headerlink" title="3.配置免密SSH(重要)"></a>3.配置免密SSH(重要)</h3><blockquote>
<p><strong>在<code>ceph-node1</code>节点操作</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# mv &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub &#x2F;root&#x2F;.ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<blockquote>
<p><strong>写个循环，把秘钥文件拷给其他机器</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# for i in 11 12 13 14
&gt; do
&gt; scp -r &#x2F;root&#x2F;.ssh&#x2F; root@192.168.140.$i:&#x2F;root&#x2F;
&gt; done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-配置主机名解析-重要"><a href="#4-配置主机名解析-重要" class="headerlink" title="4.配置主机名解析(重要)"></a>4.配置主机名解析(重要)</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# vim &#x2F;etc&#x2F;hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.140.10 ceph-node1.linux.com ceph-node1
192.168.140.11 ceph-node2.linux.com ceph-node2
192.168.140.12 ceph-node3.linux.com ceph-node3
192.168.140.13 ceph-client.linux.com ceph-client<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="把hosts文件拷贝给其他机器上"><a href="#把hosts文件拷贝给其他机器上" class="headerlink" title="把hosts文件拷贝给其他机器上"></a>把hosts文件拷贝给其他机器上</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# for i in 11 12 13
&gt; do
&gt; scp -r &#x2F;etc&#x2F;hosts root@192.168.140.$i:&#x2F;etc&#x2F;
&gt; done
hosts                                                   100%  349   541.8KB&#x2F;s   00:00    
hosts                                                   100%  349   258.4KB&#x2F;s   00:00    
hosts                                                   100%  349   286.0KB&#x2F;s   00:00<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><h3 id="1-所有主机替换默认的base源为国内，配置epel源-重要"><a href="#1-所有主机替换默认的base源为国内，配置epel源-重要" class="headerlink" title="1.所有主机替换默认的base源为国内，配置epel源(重要)"></a>1.所有主机替换默认的base源为国内，配置epel源(重要)</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node01 ~]# wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo
[root@ceph-node01 ~]# wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-7.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="2-配置ceph软件仓库-重要"><a href="#2-配置ceph软件仓库-重要" class="headerlink" title="2.配置ceph软件仓库(重要)"></a>2.配置ceph软件仓库(重要)</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# vim &#x2F;etc&#x2F;yum.repos.d&#x2F;ceph.repo
[ceph]
name&#x3D;ceph
baseurl&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ceph&#x2F;rpm-mimic&#x2F;el7&#x2F;x86_64&#x2F;
enabled&#x3D;1
gpgcheck&#x3D;0
priority&#x3D;1
 
[ceph-noarch]
name&#x3D;cephnoarch
baseurl&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ceph&#x2F;rpm-mimic&#x2F;el7&#x2F;noarch&#x2F;
enabled&#x3D;1
gpgcheck&#x3D;0
priority&#x3D;1
 
[ceph-source]
name&#x3D;Ceph source packages
baseurl&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ceph&#x2F;rpm-mimic&#x2F;el7&#x2F;SRPMS
enabled&#x3D;1
gpgcheck&#x3D;0
priority&#x3D;1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="将软件源拷贝给其他机器-重要"><a href="#将软件源拷贝给其他机器-重要" class="headerlink" title="将软件源拷贝给其他机器(重要)"></a>将软件源拷贝给其他机器(重要)</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# for i in 11 12 13
&gt; do
&gt; scp -r &#x2F;etc&#x2F;yum.repos.d&#x2F;*.repo root@192.168.140.$i:&#x2F;etc&#x2F;yum.repos.d&#x2F;
&gt; done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="清理旧缓存，生成新的缓存"><a href="#清理旧缓存，生成新的缓存" class="headerlink" title="清理旧缓存，生成新的缓存"></a>清理旧缓存，生成新的缓存</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# for i in 10 11 12 13
&gt; do
&gt; ssh root@192.168.140.$i yum clean all &amp;&amp; yum makecache fast
&gt; done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="更新系统至最新版-重要"><a href="#更新系统至最新版-重要" class="headerlink" title="更新系统至最新版(重要)"></a>更新系统至最新版(重要)</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node01 ~]# yum update -y
[root@ceph-node02 ~]# yum update -y
[root@ceph-node03 ~]# yum update -y
[root@ceph-client ~]# yum update -y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="更新完重启系统"><a href="#更新完重启系统" class="headerlink" title="更新完重启系统"></a>更新完重启系统</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# reboot
[root@ceph-node2 ~]# reboot
[root@ceph-node3 ~]# reboot
[root@ceph-client ~]# reboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-三台node节点主机新增一块硬盘"><a href="#3-三台node节点主机新增一块硬盘" class="headerlink" title="3.三台node节点主机新增一块硬盘"></a>3.三台node节点主机新增一块硬盘</h3><blockquote>
<p><strong>添加硬盘期间，虚拟机应保持关机</strong></p>
</blockquote>
<p><img src="/medias/loading.gif" data-original="https://www.wsjj.top/upload/2023/05/ceph09.png" alt="ceph09"></p>
<h2 id="三、在ceph-node1节点安装ceph-deploy自动化工具"><a href="#三、在ceph-node1节点安装ceph-deploy自动化工具" class="headerlink" title="三、在ceph-node1节点安装ceph-deploy自动化工具"></a>三、在ceph-node1节点安装ceph-deploy自动化工具</h2><blockquote>
<p><strong><code>ceph-deploy</code>是一个自动化工具，可以快速帮助我们安装<code>ceph</code></strong></p>
</blockquote>
<h3 id="1-安装ceph-deploy工具"><a href="#1-安装ceph-deploy工具" class="headerlink" title="1.安装ceph-deploy工具"></a>1.安装<code>ceph-deploy</code>工具</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# yum install -y ceph-deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="2-创建用到的目录"><a href="#2-创建用到的目录" class="headerlink" title="2.创建用到的目录"></a>2.创建用到的目录</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ~]# mkdir &#x2F;etc&#x2F;ceph
[root@ceph-node1 ~]# cd &#x2F;etc&#x2F;ceph
[root@ceph-node1 ceph]# <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h3 id="3-创建ceph集群"><a href="#3-创建ceph集群" class="headerlink" title="3.创建ceph集群"></a>3.创建ceph集群</h3><blockquote>
<p><strong>命令格式：<code>ceph-deploy new 主机名</code></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy new ceph-node1

Traceback (most recent call last):
  File &quot;&#x2F;usr&#x2F;bin&#x2F;ceph-deploy&quot;, line 18, in &lt;module&gt;
    from ceph_deploy.cli import main
  File &quot;&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_deploy&#x2F;cli.py&quot;, line 1, in &lt;module&gt;
    import pkg_resources
ImportError: No module named pkg_resources		#可以看到这里报错了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><strong>我们缺少<code>Python</code>里一个叫<code>distribute</code>的模块，使用<code>pip</code>命令安装即可！</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# pip install distribute
-bash: pip: 未找到命令<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<blockquote>
<p><strong>提示我们未找到命令，安装<code>python-pip</code>即可解决</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# yum install -y python-pip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="安装完pip命令后，返回安装distribute模块"><a href="#安装完pip命令后，返回安装distribute模块" class="headerlink" title="安装完pip命令后，返回安装distribute模块"></a>安装完pip命令后，返回安装<code>distribute</code>模块</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# pip install distribute<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="安装完模块后，即可创建ceph集群"><a href="#安装完模块后，即可创建ceph集群" class="headerlink" title="安装完模块后，即可创建ceph集群"></a>安装完模块后，即可创建<code>ceph</code>集群</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy new ceph-node1
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy new ceph-node1
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  func                          : &lt;function new at 0x7fae31615ed8&gt;
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fae30d916c8&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[ceph_deploy.cli][INFO  ]  mon                           : [&#39;ceph-node1&#39;]
[ceph_deploy.cli][INFO  ]  public_network                : None
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  cluster_network               : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  fsid                          : None
[ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph-node1][DEBUG ] find the location of an executable
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip link show
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip addr show
[ceph-node1][DEBUG ] IP addresses found: [u&#39;192.168.140.10&#39;]
[ceph_deploy.new][DEBUG ] Resolving host ceph-node1
[ceph_deploy.new][DEBUG ] Monitor ceph-node1 at 192.168.140.10
[ceph_deploy.new][DEBUG ] Monitor initial members are [&#39;ceph-node1&#39;]
[ceph_deploy.new][DEBUG ] Monitor addrs are [&#39;192.168.140.10&#39;]
[ceph_deploy.new][DEBUG ] Creating a random mon key...
[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><strong>集群创建完后，会在当前目录下生成几个文件</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ls &#x2F;etc&#x2F;ceph&#x2F;
ceph.conf  ceph-deploy-ceph.log  ceph.mon.keyring<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<ul>
<li><code>ceph.conf</code>集群配置文件</li>
<li><code>ceph.mon.keyring</code><ul>
<li><code>ceph monitor</code>认证的令牌</li>
</ul>
</li>
<li><code>ceph-deploy-ceph.log</code><ul>
<li><code>ceph-deploy</code>日志</li>
</ul>
</li>
</ul>
<h3 id="4-所有ceph-node节点安装ceph相关软件"><a href="#4-所有ceph-node节点安装ceph相关软件" class="headerlink" title="4.所有ceph-node节点安装ceph相关软件"></a>4.所有ceph-node节点安装ceph相关软件</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# for i in 10 11 12
&gt; do
&gt; ssh root@192.168.140.$i yum install -y ceph ceph-radosgw
&gt; ssh root@192.168.140.$i ceph -v
&gt; done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><strong>上面的命令和下面的命令，二选其一即可！</strong></p>
</blockquote>
<h4 id="也可以使用ceph-deploy自动化工具安装"><a href="#也可以使用ceph-deploy自动化工具安装" class="headerlink" title="也可以使用ceph-deploy自动化工具安装"></a>也可以使用ceph-deploy自动化工具安装</h4><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy install ceph-node1 ceph-node2 ceph-node3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="四、在reph-client节点安装ceph-common客户端"><a href="#四、在reph-client节点安装ceph-common客户端" class="headerlink" title="四、在reph-client节点安装ceph-common客户端"></a>四、在reph-client节点安装ceph-common客户端</h2><pre class="line-numbers language-none"><code class="language-none">[root@ceph-client ~]# yum install -y ceph-common<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="五、创建ceph-monitor"><a href="#五、创建ceph-monitor" class="headerlink" title="五、创建ceph monitor"></a>五、创建ceph monitor</h2><h3 id="1-编辑ceph-node1上的配置文件"><a href="#1-编辑ceph-node1上的配置文件" class="headerlink" title="1.编辑ceph-node1上的配置文件"></a>1.编辑ceph-node1上的配置文件</h3><blockquote>
<p><strong>配置文件路径：<code>/etc/ceph/ceph.conf</code></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# vim &#x2F;etc&#x2F;ceph&#x2F;ceph.conf
[global]
fsid &#x3D; bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
mon_initial_members &#x3D; ceph-node1
mon_host &#x3D; 192.168.140.10
auth_cluster_required &#x3D; cephx
auth_service_required &#x3D; cephx
auth_client_required &#x3D; cephx	#cephx是内部协议
public network &#x3D; 192.168.140.0&#x2F;24	#添加此段内容，定义ceph运行在那个网段上<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-monitor初始化，将ceph-node1配置为monitor"><a href="#2-monitor初始化，将ceph-node1配置为monitor" class="headerlink" title="2.monitor初始化，将ceph-node1配置为monitor"></a>2.<code>monitor</code>初始化，将<code>ceph-node1</code>配置为<code>monitor</code></h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy mon create-initial
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy mon create-initial
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc7c8687320&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x7fc7c86d7500&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  keyrings                      : None
[ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph-node1
[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-node1 ...
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph-node1][DEBUG ] find the location of an executable
[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.9.2009 Core
[ceph-node1][DEBUG ] determining if provided host has same hostname in remote
[ceph-node1][DEBUG ] get remote short hostname
[ceph-node1][DEBUG ] deploying mon to ceph-node1
[ceph-node1][DEBUG ] get remote short hostname
[ceph-node1][DEBUG ] remote hostname: ceph-node1
[ceph-node1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph-node1][DEBUG ] create the mon path if it does not exist
[ceph-node1][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;done
[ceph-node1][DEBUG ] done path does not exist: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;done
[ceph-node1][INFO  ] creating keyring file: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node1.mon.keyring
[ceph-node1][DEBUG ] create the monitor keyring file
[ceph-node1][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph-node1 --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node1.mon.keyring --setuser 167 --setgroup 167
[ceph-node1][INFO  ] unlinking keyring file &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node1.mon.keyring
[ceph-node1][DEBUG ] create a done file to avoid re-doing the mon deployment
[ceph-node1][DEBUG ] create the init path if it does not exist
[ceph-node1][INFO  ] Running command: systemctl enable ceph.target
[ceph-node1][INFO  ] Running command: systemctl enable ceph-mon@ceph-node1
[ceph-node1][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mon.target.wants&#x2F;ceph-mon@ceph-node1.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mon@.service.
[ceph-node1][INFO  ] Running command: systemctl start ceph-mon@ceph-node1
[ceph-node1][INFO  ] Running command: ceph --cluster&#x3D;ceph --admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node1.asok mon_status
[ceph-node1][DEBUG ] ********************************************************************************
[ceph-node1][DEBUG ] status for monitor: mon.ceph-node1
[ceph-node1][DEBUG ] &#123;
[ceph-node1][DEBUG ]   &quot;election_epoch&quot;: 3, 
[ceph-node1][DEBUG ]   &quot;extra_probe_peers&quot;: [], 
[ceph-node1][DEBUG ]   &quot;feature_map&quot;: &#123;
[ceph-node1][DEBUG ]     &quot;mon&quot;: [
[ceph-node1][DEBUG ]       &#123;
[ceph-node1][DEBUG ]         &quot;features&quot;: &quot;0x3ffddff8ffacfffb&quot;, 
[ceph-node1][DEBUG ]         &quot;num&quot;: 1, 
[ceph-node1][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;
[ceph-node1][DEBUG ]       &#125;
[ceph-node1][DEBUG ]     ]
[ceph-node1][DEBUG ]   &#125;, 
[ceph-node1][DEBUG ]   &quot;features&quot;: &#123;
[ceph-node1][DEBUG ]     &quot;quorum_con&quot;: &quot;4611087854031667195&quot;, 
[ceph-node1][DEBUG ]     &quot;quorum_mon&quot;: [
[ceph-node1][DEBUG ]       &quot;kraken&quot;, 
[ceph-node1][DEBUG ]       &quot;luminous&quot;, 
[ceph-node1][DEBUG ]       &quot;mimic&quot;, 
[ceph-node1][DEBUG ]       &quot;osdmap-prune&quot;
[ceph-node1][DEBUG ]     ], 
[ceph-node1][DEBUG ]     &quot;required_con&quot;: &quot;144115738102218752&quot;, 
[ceph-node1][DEBUG ]     &quot;required_mon&quot;: [
[ceph-node1][DEBUG ]       &quot;kraken&quot;, 
[ceph-node1][DEBUG ]       &quot;luminous&quot;, 
[ceph-node1][DEBUG ]       &quot;mimic&quot;, 
[ceph-node1][DEBUG ]       &quot;osdmap-prune&quot;
[ceph-node1][DEBUG ]     ]
[ceph-node1][DEBUG ]   &#125;, 
[ceph-node1][DEBUG ]   &quot;monmap&quot;: &#123;
[ceph-node1][DEBUG ]     &quot;created&quot;: &quot;2023-05-06 19:37:42.410479&quot;, 
[ceph-node1][DEBUG ]     &quot;epoch&quot;: 1, 
[ceph-node1][DEBUG ]     &quot;features&quot;: &#123;
[ceph-node1][DEBUG ]       &quot;optional&quot;: [], 
[ceph-node1][DEBUG ]       &quot;persistent&quot;: [
[ceph-node1][DEBUG ]         &quot;kraken&quot;, 
[ceph-node1][DEBUG ]         &quot;luminous&quot;, 
[ceph-node1][DEBUG ]         &quot;mimic&quot;, 
[ceph-node1][DEBUG ]         &quot;osdmap-prune&quot;
[ceph-node1][DEBUG ]       ]
[ceph-node1][DEBUG ]     &#125;, 
[ceph-node1][DEBUG ]     &quot;fsid&quot;: &quot;bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1&quot;, 
[ceph-node1][DEBUG ]     &quot;modified&quot;: &quot;2023-05-06 19:37:42.410479&quot;, 
[ceph-node1][DEBUG ]     &quot;mons&quot;: [
[ceph-node1][DEBUG ]       &#123;
[ceph-node1][DEBUG ]         &quot;addr&quot;: &quot;192.168.140.10:6789&#x2F;0&quot;, 
[ceph-node1][DEBUG ]         &quot;name&quot;: &quot;ceph-node1&quot;, 
[ceph-node1][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.140.10:6789&#x2F;0&quot;, 
[ceph-node1][DEBUG ]         &quot;rank&quot;: 0
[ceph-node1][DEBUG ]       &#125;
[ceph-node1][DEBUG ]     ]
[ceph-node1][DEBUG ]   &#125;, 
[ceph-node1][DEBUG ]   &quot;name&quot;: &quot;ceph-node1&quot;, 
[ceph-node1][DEBUG ]   &quot;outside_quorum&quot;: [], 
[ceph-node1][DEBUG ]   &quot;quorum&quot;: [
[ceph-node1][DEBUG ]     0
[ceph-node1][DEBUG ]   ], 
[ceph-node1][DEBUG ]   &quot;rank&quot;: 0, 
[ceph-node1][DEBUG ]   &quot;state&quot;: &quot;leader&quot;, 
[ceph-node1][DEBUG ]   &quot;sync_provider&quot;: []
[ceph-node1][DEBUG ] &#125;
[ceph-node1][DEBUG ] ********************************************************************************
[ceph-node1][INFO  ] monitor: mon.ceph-node1 is running
[ceph-node1][INFO  ] Running command: ceph --cluster&#x3D;ceph --admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node1.asok mon_status
[ceph_deploy.mon][INFO  ] processing monitor mon.ceph-node1
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph-node1][DEBUG ] find the location of an executable
[ceph-node1][INFO  ] Running command: ceph --cluster&#x3D;ceph --admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node1.asok mon_status
[ceph_deploy.mon][INFO  ] mon.ceph-node1 monitor has reached quorum!
[ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[ceph_deploy.mon][INFO  ] Running gatherkeys...
[ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory &#x2F;tmp&#x2F;tmp0Qv_jH
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph-node1][DEBUG ] get remote short hostname
[ceph-node1][DEBUG ] fetch remote file
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --admin-daemon&#x3D;&#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node1.asok mon_status
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --name mon. --keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;keyring auth get client.admin
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --name mon. --keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;keyring auth get client.bootstrap-mds
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --name mon. --keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;keyring auth get client.bootstrap-mgr
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --name mon. --keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;keyring auth get client.bootstrap-osd
[ceph-node1][INFO  ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph --connect-timeout&#x3D;25 --cluster&#x3D;ceph --name mon. --keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node1&#x2F;keyring auth get client.bootstrap-rgw
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[ceph_deploy.gatherkeys][INFO  ] keyring &#39;ceph.mon.keyring&#39; already exists
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[ceph_deploy.gatherkeys][INFO  ] Destroy temp directory &#x2F;tmp&#x2F;tmp0Qv_jH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-查看当前目录"><a href="#3-查看当前目录" class="headerlink" title="3.查看当前目录"></a>3.查看当前目录</h3><blockquote>
<p><strong>可以看到，多了很多以<code>keyring</code>结尾的令牌文件</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ls &#x2F;etc&#x2F;ceph&#x2F;
ceph.bootstrap-mds.keyring  ceph.bootstrap-rgw.keyring  ceph-deploy-ceph.log
ceph.bootstrap-mgr.keyring  ceph.client.admin.keyring   ceph.mon.keyring
ceph.bootstrap-osd.keyring  ceph.conf                   rbdmap<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-查看monitor状态"><a href="#4-查看monitor状态" class="headerlink" title="4.查看monitor状态"></a>4.查看<code>monitor</code>状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph health
HEALTH_OK	#正常的状态<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="5-将配置信息同步到所有ceph-node节点"><a href="#5-将配置信息同步到所有ceph-node节点" class="headerlink" title="5.将配置信息同步到所有ceph-node节点"></a>5.将配置信息同步到所有<code>ceph-node</code>节点</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy admin ceph-node1 ceph-node2 ceph-node3
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy admin ceph-node1 ceph-node2 ceph-node3
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fee074b56c8&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  client                        : [&#39;ceph-node1&#39;, &#39;ceph-node2&#39;, &#39;ceph-node3&#39;]
[ceph_deploy.cli][INFO  ]  func                          : &lt;function admin at 0x7fee07d44320&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node1
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph-node1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node2
The authenticity of host &#39;ceph-node2 (192.168.140.11)&#39; can&#39;t be established.
ECDSA key fingerprint is SHA256:HBhmMUovAvw4QMjOfLJ0JwvmtX3v5ZH&#x2F;nfQlC0pjn08.
ECDSA key fingerprint is MD5:ae:9f:42:eb:d0:64:0a:7b:7a:54:5e:95:88:d9:7c:bd.
Are you sure you want to continue connecting (yes&#x2F;no)? yes
Warning: Permanently added &#39;ceph-node2&#39; (ECDSA) to the list of known hosts.
[ceph-node2][DEBUG ] connected to host: ceph-node2 
[ceph-node2][DEBUG ] detect platform information from remote host
[ceph-node2][DEBUG ] detect machine type
[ceph-node2][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node3
The authenticity of host &#39;ceph-node3 (192.168.140.12)&#39; can&#39;t be established.
ECDSA key fingerprint is SHA256:n&#x2F;u8MvqtLiuP3pccTUPh6iVRxsgVTkkcjPZXNxKGOS4.
ECDSA key fingerprint is MD5:f9:45:27:33:c0:49:7d:d3:c7:53:9b:95:cd:95:8e:ea.
Are you sure you want to continue connecting (yes&#x2F;no)? yes
Warning: Permanently added &#39;ceph-node3&#39; (ECDSA) to the list of known hosts.
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph-node3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="6-查看其他节点上的配置文件"><a href="#6-查看其他节点上的配置文件" class="headerlink" title="6.查看其他节点上的配置文件"></a>6.查看其他节点上的配置文件</h3><blockquote>
<p><strong>如果有配置文件，那就说明都同步过来了</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node2 ~]# ls &#x2F;etc&#x2F;ceph&#x2F;
ceph.client.admin.keyring  ceph.conf  rbdmap  tmpo3DJN3

[root@ceph-node3 ~]# ls &#x2F;etc&#x2F;ceph&#x2F;
ceph.client.admin.keyring  ceph.conf  rbdmap  tmpY51J7A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-查看集群状态"><a href="#7-查看集群状态" class="headerlink" title="7.查看集群状态"></a>7.查看集群状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_OK
 
  services:
    mon: 1 daemons, quorum ceph-node1	#只有1个monitor服务
    mgr: no daemons active
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   0 B used, 0 B &#x2F; 0 B avail
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-新增多个monitor"><a href="#8-新增多个monitor" class="headerlink" title="8.新增多个monitor"></a>8.新增多个monitor</h3><blockquote>
<p><strong>防止单点故障的出现，配置多个<code>monitor</code></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy mon add ceph-node2
[root@ceph-node1 ceph]# ceph-deploy mon add ceph-node3
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy mon add ceph-node3
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : add
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4d23612320&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  mon                           : [&#39;ceph-node3&#39;]
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x7f4d23662500&gt;
[ceph_deploy.cli][INFO  ]  address                       : None
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: ceph-node3
[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node3
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph-node3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host ceph-node3
[ceph_deploy.mon][DEBUG ] using mon address by resolving host: 192.168.140.12
[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-node3 ...
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph-node3][DEBUG ] find the location of an executable
[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.9.2009 Core
[ceph-node3][DEBUG ] determining if provided host has same hostname in remote
[ceph-node3][DEBUG ] get remote short hostname
[ceph-node3][DEBUG ] adding mon to ceph-node3
[ceph-node3][DEBUG ] get remote short hostname
[ceph-node3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph-node3][DEBUG ] create the mon path if it does not exist
[ceph-node3][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node3&#x2F;done
[ceph-node3][DEBUG ] done path does not exist: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-ceph-node3&#x2F;done
[ceph-node3][INFO  ] creating keyring file: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node3.mon.keyring
[ceph-node3][DEBUG ] create the monitor keyring file
[ceph-node3][INFO  ] Running command: ceph --cluster ceph mon getmap -o &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph.ceph-node3.monmap
[ceph-node3][WARNIN] got monmap epoch 2
[ceph-node3][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph-node3 --monmap &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph.ceph-node3.monmap --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node3.mon.keyring --setuser 167 --setgroup 167
[ceph-node3][INFO  ] unlinking keyring file &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-ceph-node3.mon.keyring
[ceph-node3][DEBUG ] create a done file to avoid re-doing the mon deployment
[ceph-node3][DEBUG ] create the init path if it does not exist
[ceph-node3][INFO  ] Running command: systemctl enable ceph.target
[ceph-node3][INFO  ] Running command: systemctl enable ceph-mon@ceph-node3
[ceph-node3][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mon.target.wants&#x2F;ceph-mon@ceph-node3.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mon@.service.
[ceph-node3][INFO  ] Running command: systemctl start ceph-mon@ceph-node3
[ceph-node3][INFO  ] Running command: ceph --cluster&#x3D;ceph --admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node3.asok mon_status
[ceph-node3][WARNIN] ceph-node3 is not defined in &#96;mon initial members&#96;
[ceph-node3][INFO  ] Running command: ceph --cluster&#x3D;ceph --admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.ceph-node3.asok mon_status
[ceph-node3][DEBUG ] ********************************************************************************
[ceph-node3][DEBUG ] status for monitor: mon.ceph-node3
[ceph-node3][DEBUG ] &#123;
[ceph-node3][DEBUG ]   &quot;election_epoch&quot;: 1, 
[ceph-node3][DEBUG ]   &quot;extra_probe_peers&quot;: [
[ceph-node3][DEBUG ]     &quot;192.168.140.11:6789&#x2F;0&quot;
[ceph-node3][DEBUG ]   ], 
[ceph-node3][DEBUG ]   &quot;feature_map&quot;: &#123;
[ceph-node3][DEBUG ]     &quot;mon&quot;: [
[ceph-node3][DEBUG ]       &#123;
[ceph-node3][DEBUG ]         &quot;features&quot;: &quot;0x3ffddff8ffacfffb&quot;, 
[ceph-node3][DEBUG ]         &quot;num&quot;: 1, 
[ceph-node3][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;
[ceph-node3][DEBUG ]       &#125;
[ceph-node3][DEBUG ]     ]
[ceph-node3][DEBUG ]   &#125;, 
[ceph-node3][DEBUG ]   &quot;features&quot;: &#123;
[ceph-node3][DEBUG ]     &quot;quorum_con&quot;: &quot;0&quot;, 
[ceph-node3][DEBUG ]     &quot;quorum_mon&quot;: [], 
[ceph-node3][DEBUG ]     &quot;required_con&quot;: &quot;144115188346404864&quot;, 
[ceph-node3][DEBUG ]     &quot;required_mon&quot;: [
[ceph-node3][DEBUG ]       &quot;kraken&quot;, 
[ceph-node3][DEBUG ]       &quot;luminous&quot;, 
[ceph-node3][DEBUG ]       &quot;mimic&quot;, 
[ceph-node3][DEBUG ]       &quot;osdmap-prune&quot;
[ceph-node3][DEBUG ]     ]
[ceph-node3][DEBUG ]   &#125;, 
[ceph-node3][DEBUG ]   &quot;monmap&quot;: &#123;
[ceph-node3][DEBUG ]     &quot;created&quot;: &quot;2023-05-06 19:37:42.410479&quot;, 
[ceph-node3][DEBUG ]     &quot;epoch&quot;: 3, 
[ceph-node3][DEBUG ]     &quot;features&quot;: &#123;
[ceph-node3][DEBUG ]       &quot;optional&quot;: [], 
[ceph-node3][DEBUG ]       &quot;persistent&quot;: [
[ceph-node3][DEBUG ]         &quot;kraken&quot;, 
[ceph-node3][DEBUG ]         &quot;luminous&quot;, 
[ceph-node3][DEBUG ]         &quot;mimic&quot;, 
[ceph-node3][DEBUG ]         &quot;osdmap-prune&quot;
[ceph-node3][DEBUG ]       ]
[ceph-node3][DEBUG ]     &#125;, 
[ceph-node3][DEBUG ]     &quot;fsid&quot;: &quot;bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1&quot;, 
[ceph-node3][DEBUG ]     &quot;modified&quot;: &quot;2023-05-06 19:48:46.297830&quot;, 
[ceph-node3][DEBUG ]     &quot;mons&quot;: [
[ceph-node3][DEBUG ]       &#123;
[ceph-node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.140.10:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-node1&quot;, 
[ceph-node3][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.140.10:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;rank&quot;: 0
[ceph-node3][DEBUG ]       &#125;, 
[ceph-node3][DEBUG ]       &#123;
[ceph-node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.140.11:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-node2&quot;, 
[ceph-node3][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.140.11:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;rank&quot;: 1
[ceph-node3][DEBUG ]       &#125;, 
[ceph-node3][DEBUG ]       &#123;
[ceph-node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.140.12:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;name&quot;: &quot;ceph-node3&quot;, 
[ceph-node3][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.140.12:6789&#x2F;0&quot;, 
[ceph-node3][DEBUG ]         &quot;rank&quot;: 2
[ceph-node3][DEBUG ]       &#125;
[ceph-node3][DEBUG ]     ]
[ceph-node3][DEBUG ]   &#125;, 
[ceph-node3][DEBUG ]   &quot;name&quot;: &quot;ceph-node3&quot;, 
[ceph-node3][DEBUG ]   &quot;outside_quorum&quot;: [], 
[ceph-node3][DEBUG ]   &quot;quorum&quot;: [], 
[ceph-node3][DEBUG ]   &quot;rank&quot;: 2, 
[ceph-node3][DEBUG ]   &quot;state&quot;: &quot;electing&quot;, 
[ceph-node3][DEBUG ]   &quot;sync_provider&quot;: []
[ceph-node3][DEBUG ] &#125;
[ceph-node3][DEBUG ] ********************************************************************************
[ceph-node3][INFO  ] monitor: mon.ceph-node3 is running		#可以看到这里我们新添加的monitor已经运行了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="9-查看集群状态"><a href="#9-查看集群状态" class="headerlink" title="9.查看集群状态"></a>9.查看集群状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_WARN
            clock skew detected on mon.ceph-node2, mon.ceph-node3
 
  services:
    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3	#可以看到这里已经有3个monitor了
    mgr: no daemons active
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   0 B used, 0 B &#x2F; 0 B avail
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="六、创建ceph-mgr"><a href="#六、创建ceph-mgr" class="headerlink" title="六、创建ceph mgr"></a>六、创建ceph mgr</h2><blockquote>
<p><code>ceph</code>自<code>L</code>版本后，添加<code>Ceph Manager Daemon</code>，简称<code>ceph-mgr</code><br>该组件的出现主要是为了缓解<code>ceph-monitor</code>的压力，分担了<code>moniotr</code>的工作，例如&#x3D;&#x3D;插件管理&#x3D;&#x3D;等，以更好的管理集群。</p>
</blockquote>
<h3 id="1-在ceph-node1节点创建ceph-mgr服务"><a href="#1-在ceph-node1节点创建ceph-mgr服务" class="headerlink" title="1.在ceph-node1节点创建ceph mgr服务"></a>1.在ceph-node1节点创建ceph mgr服务</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy mgr create ceph-node1
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy mgr create ceph-node1
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  mgr                           : [(&#39;ceph-node1&#39;, &#39;ceph-node1&#39;)]
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : create
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f78a6252b90&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mgr at 0x7f78a6b33230&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-node1:ceph-node1
[ceph-node1][DEBUG ] connected to host: ceph-node1 
[ceph-node1][DEBUG ] detect platform information from remote host
[ceph-node1][DEBUG ] detect machine type
[ceph_deploy.mgr][INFO  ] Distro info: CentOS Linux 7.9.2009 Core
[ceph_deploy.mgr][DEBUG ] remote host will use systemd
[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-node1
[ceph-node1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph-node1][WARNIN] mgr keyring does not exist yet, creating one
[ceph-node1][DEBUG ] create a keyring file
[ceph-node1][DEBUG ] create path recursively if it doesn&#39;t exist
[ceph-node1][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-mgr --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-mgr&#x2F;ceph.keyring auth get-or-create mgr.ceph-node1 mon allow profile mgr osd allow * mds allow * -o &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mgr&#x2F;ceph-ceph-node1&#x2F;keyring
[ceph-node1][INFO  ] Running command: systemctl enable ceph-mgr@ceph-node1
[ceph-node1][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mgr.target.wants&#x2F;ceph-mgr@ceph-node1.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mgr@.service.
[ceph-node1][INFO  ] Running command: systemctl start ceph-mgr@ceph-node1
[ceph-node1][INFO  ] Running command: systemctl enable ceph.target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-查看集群状态"><a href="#2-查看集群状态" class="headerlink" title="2.查看集群状态"></a>2.查看集群状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_WARN
            OSD count 0 &lt; osd_pool_default_size 3
            clock skew detected on mon.ceph-node2, mon.ceph-node3
 
  services:
    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3
    mgr: ceph-node1(active)		#可以看到mgr组件在node1运行
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   0 B used, 0 B &#x2F; 0 B avail
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-添加多个ceph-mgr"><a href="#3-添加多个ceph-mgr" class="headerlink" title="3.添加多个ceph mgr"></a>3.添加多个ceph mgr</h3><blockquote>
<p><strong>同理，避免单点故障</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy mgr create ceph-node2
[root@ceph-node1 ceph]# ceph-deploy mgr create ceph-node3
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy mgr create ceph-node3
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  mgr                           : [(&#39;ceph-node3&#39;, &#39;ceph-node3&#39;)]
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : create
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5e2921db90&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  func                          : &lt;function mgr at 0x7f5e29afe230&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-node3:ceph-node3
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph_deploy.mgr][INFO  ] Distro info: CentOS Linux 7.9.2009 Core
[ceph_deploy.mgr][DEBUG ] remote host will use systemd
[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-node3
[ceph-node3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph-node3][WARNIN] mgr keyring does not exist yet, creating one
[ceph-node3][DEBUG ] create a keyring file
[ceph-node3][DEBUG ] create path recursively if it doesn&#39;t exist
[ceph-node3][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-mgr --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-mgr&#x2F;ceph.keyring auth get-or-create mgr.ceph-node3 mon allow profile mgr osd allow * mds allow * -o &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mgr&#x2F;ceph-ceph-node3&#x2F;keyring
[ceph-node3][INFO  ] Running command: systemctl enable ceph-mgr@ceph-node3
[ceph-node3][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mgr.target.wants&#x2F;ceph-mgr@ceph-node3.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mgr@.service.
[ceph-node3][INFO  ] Running command: systemctl start ceph-mgr@ceph-node3
[ceph-node3][INFO  ] Running command: systemctl enable ceph.target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-查看集群状态"><a href="#4-查看集群状态" class="headerlink" title="4.查看集群状态"></a>4.查看集群状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_WARN
            OSD count 0 &lt; osd_pool_default_size 3
            clock skew detected on mon.ceph-node2, mon.ceph-node3
 
  services:
    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3
    mgr: ceph-node1(active), standbys: ceph-node2, ceph-node3	#可以看到，已经添加了多个mgr，但是只有node1在活动，其他节点作为备用节点
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   0 B used, 0 B &#x2F; 0 B avail
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="七、创建OSD-数据盘"><a href="#七、创建OSD-数据盘" class="headerlink" title="七、创建OSD(数据盘)"></a>七、创建OSD(数据盘)</h2><h3 id="1-检查是否新增了硬盘"><a href="#1-检查是否新增了硬盘" class="headerlink" title="1.检查是否新增了硬盘"></a>1.检查是否新增了硬盘</h3><blockquote>
<p><strong>如果还没有新增硬盘，请回到第二步添加虚拟硬盘！</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# for i in 10 11 12
&gt; do
&gt; ssh root@192.168.140.$i lsblk | grep sdb
&gt; done
sdb               8:16   0   20G  0 disk 
sdb               8:16   0   20G  0 disk 
sdb               8:16   0   20G  0 disk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-初始化磁盘，清空磁盘数据"><a href="#2-初始化磁盘，清空磁盘数据" class="headerlink" title="2.初始化磁盘，清空磁盘数据"></a>2.初始化磁盘，清空磁盘数据</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy disk zap ceph-node1 &#x2F;dev&#x2F;sdb
[root@ceph-node1 ceph]# ceph-deploy disk zap ceph-node2 &#x2F;dev&#x2F;sdb
[root@ceph-node1 ceph]# ceph-deploy disk zap ceph-node3 &#x2F;dev&#x2F;sdb
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy disk zap ceph-node3 &#x2F;dev&#x2F;sdb
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  debug                         : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  subcommand                    : zap
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7faf801fd830&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  host                          : ceph-node3
[ceph_deploy.cli][INFO  ]  func                          : &lt;function disk at 0x7faf80238a28&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  disk                          : [&#39;&#x2F;dev&#x2F;sdb&#39;]
[ceph_deploy.osd][DEBUG ] zapping &#x2F;dev&#x2F;sdb on ceph-node3
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph-node3][DEBUG ] find the location of an executable
[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.9.2009 Core
[ceph-node3][DEBUG ] zeroing last few blocks of device
[ceph-node3][DEBUG ] find the location of an executable
[ceph-node3][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ceph-volume lvm zap &#x2F;dev&#x2F;sdb
[ceph-node3][WARNIN] --&gt; Zapping: &#x2F;dev&#x2F;sdb
[ceph-node3][WARNIN] --&gt; --destroy was not specified, but zapping a whole device will remove the partition table
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;dev&#x2F;sdb bs&#x3D;1M count&#x3D;10 conv&#x3D;fsync
[ceph-node3][WARNIN]  stderr: 记录了10+0 的读入
[ceph-node3][WARNIN] 记录了10+0 的写出
[ceph-node3][WARNIN] 10485760字节(10 MB)已复制，0.0090652 秒，1.2 GB&#x2F;秒
[ceph-node3][WARNIN] --&gt; Zapping successful for: &lt;Raw Device: &#x2F;dev&#x2F;sdb&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-将磁盘创建为osd"><a href="#3-将磁盘创建为osd" class="headerlink" title="3.将磁盘创建为osd"></a>3.将磁盘创建为<code>osd</code></h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph-deploy osd create --data &#x2F;dev&#x2F;sdb ceph-node1
[root@ceph-node1 ceph]# ceph-deploy osd create --data &#x2F;dev&#x2F;sdb ceph-node2
[root@ceph-node1 ceph]# ceph-deploy osd create --data &#x2F;dev&#x2F;sdb ceph-node3
#以下是部分提示信息
[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf
[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy osd create --data &#x2F;dev&#x2F;sdb ceph-node3
[ceph_deploy.cli][INFO  ] ceph-deploy options:
[ceph_deploy.cli][INFO  ]  verbose                       : False
[ceph_deploy.cli][INFO  ]  bluestore                     : None
[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9ffdc20950&gt;
[ceph_deploy.cli][INFO  ]  cluster                       : ceph
[ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[ceph_deploy.cli][INFO  ]  block_wal                     : None
[ceph_deploy.cli][INFO  ]  default_release               : False
[ceph_deploy.cli][INFO  ]  username                      : None
[ceph_deploy.cli][INFO  ]  journal                       : None
[ceph_deploy.cli][INFO  ]  subcommand                    : create
[ceph_deploy.cli][INFO  ]  host                          : ceph-node3
[ceph_deploy.cli][INFO  ]  filestore                     : None
[ceph_deploy.cli][INFO  ]  func                          : &lt;function osd at 0x7f9ffdc579b0&gt;
[ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[ceph_deploy.cli][INFO  ]  zap_disk                      : False
[ceph_deploy.cli][INFO  ]  data                          : &#x2F;dev&#x2F;sdb
[ceph_deploy.cli][INFO  ]  block_db                      : None
[ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : &#x2F;etc&#x2F;ceph&#x2F;dmcrypt-keys
[ceph_deploy.cli][INFO  ]  quiet                         : False
[ceph_deploy.cli][INFO  ]  debug                         : False
[ceph_deploy.osd][DEBUG ] Creating OSD on cluster ceph with data device &#x2F;dev&#x2F;sdb
[ceph-node3][DEBUG ] connected to host: ceph-node3 
[ceph-node3][DEBUG ] detect platform information from remote host
[ceph-node3][DEBUG ] detect machine type
[ceph-node3][DEBUG ] find the location of an executable
[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.9.2009 Core
[ceph_deploy.osd][DEBUG ] Deploying osd to ceph-node3
[ceph-node3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;&#123;cluster&#125;.conf
[ceph-node3][WARNIN] osd keyring does not exist yet, creating one
[ceph-node3][DEBUG ] create a keyring file
[ceph-node3][DEBUG ] find the location of an executable
[ceph-node3][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ceph-volume --cluster ceph lvm create --bluestore --data &#x2F;dev&#x2F;sdb
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph-authtool --gen-print-key
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph --cluster ceph --name client.bootstrap-osd --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-osd&#x2F;ceph.keyring -i - osd new 85add657-24b1-4a4f-a68b-a3d7d67d45a9
[ceph-node3][WARNIN] Running command: &#x2F;usr&#x2F;sbin&#x2F;vgcreate --force --yes ceph-0b50d828-e42a-4226-8418-67369ec97bca &#x2F;dev&#x2F;sdb
[ceph-node3][WARNIN]  stdout: Physical volume &quot;&#x2F;dev&#x2F;sdb&quot; successfully created.
[ceph-node3][WARNIN]  stdout: Volume group &quot;ceph-0b50d828-e42a-4226-8418-67369ec97bca&quot; successfully created
[ceph-node3][WARNIN] Running command: &#x2F;usr&#x2F;sbin&#x2F;lvcreate --yes -l 100%FREE -n osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9 ceph-0b50d828-e42a-4226-8418-67369ec97bca
[ceph-node3][WARNIN]  stdout: Logical volume &quot;osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9&quot; created.
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph-authtool --gen-print-key
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;mount -t tmpfs tmpfs &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -h ceph:ceph &#x2F;dev&#x2F;ceph-0b50d828-e42a-4226-8418-67369ec97bca&#x2F;osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;dev&#x2F;dm-2
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ln -s &#x2F;dev&#x2F;ceph-0b50d828-e42a-4226-8418-67369ec97bca&#x2F;osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;block
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph --cluster ceph --name client.bootstrap-osd --keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-osd&#x2F;ceph.keyring mon getmap -o &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;activate.monmap
[ceph-node3][WARNIN]  stderr: got monmap epoch 3
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph-authtool &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;keyring --create-keyring --name osd.2 --add-key AQBwRFZkRSJCJBAAWolZtOSfTuFfLaSRWlyBnA&#x3D;&#x3D;
[ceph-node3][WARNIN]  stdout: creating &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;keyring
[ceph-node3][WARNIN] added entity osd.2 auth auth(auid &#x3D; 18446744073709551615 key&#x3D;AQBwRFZkRSJCJBAAWolZtOSfTuFfLaSRWlyBnA&#x3D;&#x3D; with 0 caps)
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;keyring
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph-osd --cluster ceph --osd-objectstore bluestore --mkfs -i 2 --monmap &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;activate.monmap --keyfile - --osd-data &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F; --osd-uuid 85add657-24b1-4a4f-a68b-a3d7d67d45a9 --setuser ceph --setgroup ceph
[ceph-node3][WARNIN] --&gt; ceph-volume lvm prepare successful for: &#x2F;dev&#x2F;sdb
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ceph-bluestore-tool --cluster&#x3D;ceph prime-osd-dir --dev &#x2F;dev&#x2F;ceph-0b50d828-e42a-4226-8418-67369ec97bca&#x2F;osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9 --path &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2 --no-mon-config
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;ln -snf &#x2F;dev&#x2F;ceph-0b50d828-e42a-4226-8418-67369ec97bca&#x2F;osd-block-85add657-24b1-4a4f-a68b-a3d7d67d45a9 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;block
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -h ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2&#x2F;block
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;dev&#x2F;dm-2
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-2
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;systemctl enable ceph-volume@lvm-2-85add657-24b1-4a4f-a68b-a3d7d67d45a9
[ceph-node3][WARNIN]  stderr: Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;ceph-volume@lvm-2-85add657-24b1-4a4f-a68b-a3d7d67d45a9.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-volume@.service.
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;systemctl enable --runtime ceph-osd@2
[ceph-node3][WARNIN]  stderr: Created symlink from &#x2F;run&#x2F;systemd&#x2F;system&#x2F;ceph-osd.target.wants&#x2F;ceph-osd@2.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-osd@.service.
[ceph-node3][WARNIN] Running command: &#x2F;bin&#x2F;systemctl start ceph-osd@2
[ceph-node3][WARNIN] --&gt; ceph-volume lvm activate successful for osd ID: 2
[ceph-node3][WARNIN] --&gt; ceph-volume lvm create successful for: &#x2F;dev&#x2F;sdb
[ceph-node3][INFO  ] checking OSD status...
[ceph-node3][DEBUG ] find the location of an executable
[ceph-node3][INFO  ] Running command: &#x2F;bin&#x2F;ceph --cluster&#x3D;ceph osd stat --format&#x3D;json
[ceph_deploy.osd][DEBUG ] Host ceph-node3 is now ready for osd use.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-查看集群状态-1"><a href="#4-查看集群状态-1" class="headerlink" title="4.查看集群状态"></a>4.查看集群状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3
    mgr: ceph-node1(active), standbys: ceph-node2, ceph-node3
    osd: 3 osds: 3 up, 3 in		#一共3个osd
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   3.0 GiB used, 57 GiB &#x2F; 60 GiB avail	#一共60G的空间，所有osd之和
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><strong>如果您能坚持到这里，那么恭喜你，<code>ceph</code>基本集群环境已经部署完成了！</strong></p>
</blockquote>
<h3 id="拓展：集群节点扩容-即集群添加新节点"><a href="#拓展：集群节点扩容-即集群添加新节点" class="headerlink" title="拓展：集群节点扩容(即集群添加新节点)"></a>拓展：集群节点扩容(即集群添加新节点)</h3><ul>
<li>新节点配置系统基础环境(主机名解析、时间同步、ceph仓库)</li>
<li>新节点安装<code>ceph</code>、<code>ceph-radosgw</code>软件 </li>
<li>将集群文件同步给新节点<ul>
<li>#ceph-deploy admin &lt;新节点&gt;</li>
</ul>
</li>
<li>按需求在新节点上添加<code>osd</code></li>
</ul>
<h2 id="八、启用ceph-dashboard插件-可选的"><a href="#八、启用ceph-dashboard插件-可选的" class="headerlink" title="八、启用ceph dashboard插件(可选的)"></a>八、启用ceph dashboard插件(可选的)</h2><blockquote>
<p><strong><code>ceph dashboard</code>主要提供<code>webUI</code>界面</strong></p>
</blockquote>
<h3 id="1-确认mgr主节点"><a href="#1-确认mgr主节点" class="headerlink" title="1.确认mgr主节点"></a>1.确认mgr主节点</h3><blockquote>
<p><strong>以下操作将在<code>mgr</code>的主节点操作！</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph -s
  cluster:
    id:     bf6cea08-aaf9-4f2c-9316-f1d1a66fcbc1
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3
    mgr: ceph-node1(active), standbys: ceph-node2, ceph-node3	#可以看到node1是活动的主节点
    osd: 3 osds: 3 up, 3 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0  objects, 0 B
    usage:   3.0 GiB used, 57 GiB &#x2F; 60 GiB avail
    pgs:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-开启dashboard模块"><a href="#2-开启dashboard模块" class="headerlink" title="2.开启dashboard模块"></a>2.开启<code>dashboard</code>模块</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph mgr module enable dashboard<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<blockquote>
<p><strong>如果提示<code>Error ENOENT: all mgr daemons do not support module &#39;dashboard&#39;, pass --force to force enablement</code>则需要在所有<code>mgr</code>节点安装<code>ceph-mgr-dashboard</code>软件</strong></p>
</blockquote>
<h3 id="3-查看所有模块"><a href="#3-查看所有模块" class="headerlink" title="3.查看所有模块"></a>3.查看所有模块</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph mgr module ls

&#123;
    &quot;enabled_modules&quot;: [	#已启用的模块
        &quot;balancer&quot;,
        &quot;crash&quot;,
        &quot;dashboard&quot;,
        &quot;iostat&quot;,
        &quot;restful&quot;,
        &quot;status&quot;
    ],
    &quot;disabled_modules&quot;: [	#未启用的模块
        &#123;
            &quot;name&quot;: &quot;hello&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;influx&quot;,
            &quot;can_run&quot;: false,
            &quot;error_string&quot;: &quot;influxdb python module not found&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;localpool&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;prometheus&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;selftest&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;smart&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;telegraf&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;telemetry&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;,
        &#123;
            &quot;name&quot;: &quot;zabbix&quot;,
            &quot;can_run&quot;: true,
            &quot;error_string&quot;: &quot;&quot;
        &#125;
    ]
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-创建自签证书"><a href="#4-创建自签证书" class="headerlink" title="4.创建自签证书"></a>4.创建自签证书</h3><blockquote>
<p><strong>因为<code>dashboard</code>模块的<code>web</code>界面提供<code>https</code>服务，我们需要生成<code>ssl</code>证书</strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# ceph dashboard create-self-signed-cert
Self-signed certificate created<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="5-生成dashboard需要的自签证书"><a href="#5-生成dashboard需要的自签证书" class="headerlink" title="5.生成dashboard需要的自签证书"></a>5.生成<code>dashboard</code>需要的自签证书</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 ceph]# mkdir &#x2F;etc&#x2F;mgr-dashboard
[root@ceph-node1 ceph]# cd &#x2F;etc&#x2F;mgr-dashboard<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# openssl req -new -nodes -x509 -subj &quot;&#x2F;O&#x3D;IT-ceph&#x2F;CN&#x3D;cn&quot; -days 3650 -keyout dashboard.key -out dashboard.crt -extensions v3_ca
Generating a 2048 bit RSA private key
...................................................+++
.............................+++
writing new private key to &#39;dashboard.key&#39;
-----<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ls
dashboard.crt  dashboard.key<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="6-修改dashboard访问地址"><a href="#6-修改dashboard访问地址" class="headerlink" title="6.修改dashboard访问地址"></a>6.修改<code>dashboard</code>访问地址</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ceph config set mgr mgr&#x2F;dashboard&#x2F;server_addr 192.168.140.10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="7-修改dashboard监听端口-可选的"><a href="#7-修改dashboard监听端口-可选的" class="headerlink" title="7.修改dashboard监听端口(可选的)"></a>7.修改<code>dashboard</code>监听端口(可选的)</h3><blockquote>
<p><strong><code>dashboard</code>默认监听端口：<code>8443</code></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ceph config set mgr mgr&#x2F;dashboard&#x2F;server_port 8888<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="8-重启dashboard让修改生效"><a href="#8-重启dashboard让修改生效" class="headerlink" title="8.重启dashboard让修改生效"></a>8.重启<code>dashboard</code>让修改生效</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ceph mgr module disable dashboard
[root@ceph-node1 mgr-dashboard]# ceph mgr module enable dashboard<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="9-查看mgr-service状态"><a href="#9-查看mgr-service状态" class="headerlink" title="9.查看mgr service状态"></a>9.查看<code>mgr service</code>状态</h3><pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ceph mgr services
&#123;
    &quot;dashboard&quot;: &quot;https:&#x2F;&#x2F;192.168.140.10:8888&#x2F;&quot;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-设置dashboard提供web界面认证的用户和密码"><a href="#10-设置dashboard提供web界面认证的用户和密码" class="headerlink" title="10.设置dashboard提供web界面认证的用户和密码"></a>10.设置<code>dashboard</code>提供<code>web</code>界面认证的用户和密码</h3><blockquote>
<p><strong>用户名：<code>wsjj</code> 密码：<code>redhat</code></strong></p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">[root@ceph-node1 mgr-dashboard]# ceph dashboard set-login-credentials wsjj redhat
Username and password updated<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="11-浏览器测试访问"><a href="#11-浏览器测试访问" class="headerlink" title="11.浏览器测试访问"></a>11.浏览器测试访问</h3><blockquote>
<p><strong>因为我们是&#x3D;&#x3D;自签证书&#x3D;&#x3D;，并不是网上公认的公有<code>CA</code>颁发的证书，所以这是正常提示！</strong></p>
</blockquote>
<p><img src="/medias/loading.gif" data-original="https://www.wsjj.top/upload/2023/05/ceph10.png" alt="ceph10"></p>
<p><img src="/medias/loading.gif" data-original="https://www.wsjj.top/upload/2023/05/ceph12.png" alt="ceph12"></p>
<p><img src="/medias/loading.gif" data-original="https://www.wsjj.top/upload/2023/05/ceph13.png" alt="ceph13"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://blog.wangshengjj.work">网笙久久</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.wangshengjj.work/2023/05/06/105/">https://blog.wangshengjj.work/2023/05/06/105/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.wangshengjj.work" target="_blank">WangShengJJのblog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%9B%86%E7%BE%A4/">集群</a><a class="post-meta__tags" href="/tags/linux/">linux</a><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E9%9B%86%E7%BE%A4/">分布式存储集群</a><a class="post-meta__tags" href="/tags/ceph/">ceph</a><a class="post-meta__tags" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/">服务器搭建</a><a class="post-meta__tags" href="/tags/linux%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8/">linux搭建服务器</a><a class="post-meta__tags" href="/tags/ceph-deploy/">ceph-deploy</a></div><div class="post_share"><div class="social-share" data-image="https://www.dmoe.cc/random.php" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/06/106/" title="【Linux存储系列教程】ceph存储的使用"><img class="cover" src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【Linux存储系列教程】ceph存储的使用</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/06/104/" title="【Linux存储系列教程】ceph的架构和原理"><img class="cover" src="/medias/loading.gif" data-original="https://api.ghser.com/random/api.php" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【Linux存储系列教程】ceph的架构和原理</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/05/06/106/" title="【Linux存储系列教程】ceph存储的使用"><img class="cover" src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-06</div><div class="title">【Linux存储系列教程】ceph存储的使用</div></div></a></div><div><a href="/2023/05/06/104/" title="【Linux存储系列教程】ceph的架构和原理"><img class="cover" src="/medias/loading.gif" data-original="https://api.ghser.com/random/api.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-06</div><div class="title">【Linux存储系列教程】ceph的架构和原理</div></div></a></div><div><a href="/2023/04/23/94/" title="【Linux基础服务教程】Redis分片集群"><img class="cover" src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-23</div><div class="title">【Linux基础服务教程】Redis分片集群</div></div></a></div><div><a href="/2023/04/25/98/" title="【Linux集群系列教程】LB集群(keepalived结合LVS)+LAMP环境+WordPress博客"><img class="cover" src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-25</div><div class="title">【Linux集群系列教程】LB集群(keepalived结合LVS)+LAMP环境+WordPress博客</div></div></a></div><div><a href="/2023/04/02/71/" title="【Linux基础服务教程】httpd(Apache)配置https访问"><img class="cover" src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-02</div><div class="title">【Linux基础服务教程】httpd(Apache)配置https访问</div></div></a></div><div><a href="/2023/05/08/107/" title="【Linux存储系列教程】zookeeper中间件"><img class="cover" src="/medias/loading.gif" data-original="https://api.ghser.com/random/api.php" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-08</div><div class="title">【Linux存储系列教程】zookeeper中间件</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/medias/loading.gif" data-original="https://www.wangshengjj.work/upload/2022/10/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">网笙久久</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">139</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">185</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">261</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wangshengjj"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wangshengjj" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:wangshengjj@wangshengjj.work" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://www.wangshengjj.work" target="_blank" title="Blog"><i class="fa fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到网笙久久的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%80%90Linux%E5%AD%98%E5%82%A8%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E3%80%91ceph-mimic%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">1.</span> <span class="toc-text">【Linux存储系列教程】ceph-mimic集群部署</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%AE%9E%E9%AA%8C%E5%87%86%E5%A4%87"><span class="toc-number">1.1.</span> <span class="toc-text">一、实验准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%A7%84%E5%88%92%E4%B8%BB%E6%9C%BA"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.规划主机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%89%80%E6%9C%89%E4%B8%BB%E6%9C%BA%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8CSElinux%E3%80%81%E9%85%8D%E7%BD%AE%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5-%E9%87%8D%E8%A6%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">2.所有主机关闭防火墙和SElinux、配置时间同步(重要)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">设置同步时间计划任务</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%85%8D%E7%BD%AE%E5%85%8D%E5%AF%86SSH-%E9%87%8D%E8%A6%81"><span class="toc-number">1.1.3.</span> <span class="toc-text">3.配置免密SSH(重要)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%85%8D%E7%BD%AE%E4%B8%BB%E6%9C%BA%E5%90%8D%E8%A7%A3%E6%9E%90-%E9%87%8D%E8%A6%81"><span class="toc-number">1.1.4.</span> <span class="toc-text">4.配置主机名解析(重要)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%8Ahosts%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D%E7%BB%99%E5%85%B6%E4%BB%96%E6%9C%BA%E5%99%A8%E4%B8%8A"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">把hosts文件拷贝给其他机器上</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">1.2.</span> <span class="toc-text">二、环境准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%89%80%E6%9C%89%E4%B8%BB%E6%9C%BA%E6%9B%BF%E6%8D%A2%E9%BB%98%E8%AE%A4%E7%9A%84base%E6%BA%90%E4%B8%BA%E5%9B%BD%E5%86%85%EF%BC%8C%E9%85%8D%E7%BD%AEepel%E6%BA%90-%E9%87%8D%E8%A6%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.所有主机替换默认的base源为国内，配置epel源(重要)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%85%8D%E7%BD%AEceph%E8%BD%AF%E4%BB%B6%E4%BB%93%E5%BA%93-%E9%87%8D%E8%A6%81"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.配置ceph软件仓库(重要)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E8%BD%AF%E4%BB%B6%E6%BA%90%E6%8B%B7%E8%B4%9D%E7%BB%99%E5%85%B6%E4%BB%96%E6%9C%BA%E5%99%A8-%E9%87%8D%E8%A6%81"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">将软件源拷贝给其他机器(重要)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B8%85%E7%90%86%E6%97%A7%E7%BC%93%E5%AD%98%EF%BC%8C%E7%94%9F%E6%88%90%E6%96%B0%E7%9A%84%E7%BC%93%E5%AD%98"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">清理旧缓存，生成新的缓存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E7%B3%BB%E7%BB%9F%E8%87%B3%E6%9C%80%E6%96%B0%E7%89%88-%E9%87%8D%E8%A6%81"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">更新系统至最新版(重要)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%AE%8C%E9%87%8D%E5%90%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">更新完重启系统</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%89%E5%8F%B0node%E8%8A%82%E7%82%B9%E4%B8%BB%E6%9C%BA%E6%96%B0%E5%A2%9E%E4%B8%80%E5%9D%97%E7%A1%AC%E7%9B%98"><span class="toc-number">1.2.3.</span> <span class="toc-text">3.三台node节点主机新增一块硬盘</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9C%A8ceph-node1%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85ceph-deploy%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7"><span class="toc-number">1.3.</span> <span class="toc-text">三、在ceph-node1节点安装ceph-deploy自动化工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%85ceph-deploy%E5%B7%A5%E5%85%B7"><span class="toc-number">1.3.1.</span> <span class="toc-text">1.安装ceph-deploy工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E7%94%A8%E5%88%B0%E7%9A%84%E7%9B%AE%E5%BD%95"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.创建用到的目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%88%9B%E5%BB%BAceph%E9%9B%86%E7%BE%A4"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.创建ceph集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%AE%8Cpip%E5%91%BD%E4%BB%A4%E5%90%8E%EF%BC%8C%E8%BF%94%E5%9B%9E%E5%AE%89%E8%A3%85distribute%E6%A8%A1%E5%9D%97"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">安装完pip命令后，返回安装distribute模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%AE%8C%E6%A8%A1%E5%9D%97%E5%90%8E%EF%BC%8C%E5%8D%B3%E5%8F%AF%E5%88%9B%E5%BB%BAceph%E9%9B%86%E7%BE%A4"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">安装完模块后，即可创建ceph集群</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%89%80%E6%9C%89ceph-node%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85ceph%E7%9B%B8%E5%85%B3%E8%BD%AF%E4%BB%B6"><span class="toc-number">1.3.4.</span> <span class="toc-text">4.所有ceph-node节点安装ceph相关软件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8ceph-deploy%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">也可以使用ceph-deploy自动化工具安装</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%9C%A8reph-client%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85ceph-common%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">1.4.</span> <span class="toc-text">四、在reph-client节点安装ceph-common客户端</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%88%9B%E5%BB%BAceph-monitor"><span class="toc-number">1.5.</span> <span class="toc-text">五、创建ceph monitor</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BC%96%E8%BE%91ceph-node1%E4%B8%8A%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">1.编辑ceph-node1上的配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-monitor%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E5%B0%86ceph-node1%E9%85%8D%E7%BD%AE%E4%B8%BAmonitor"><span class="toc-number">1.5.2.</span> <span class="toc-text">2.monitor初始化，将ceph-node1配置为monitor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95"><span class="toc-number">1.5.3.</span> <span class="toc-text">3.查看当前目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9F%A5%E7%9C%8Bmonitor%E7%8A%B6%E6%80%81"><span class="toc-number">1.5.4.</span> <span class="toc-text">4.查看monitor状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%B0%86%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%90%8C%E6%AD%A5%E5%88%B0%E6%89%80%E6%9C%89ceph-node%E8%8A%82%E7%82%B9"><span class="toc-number">1.5.5.</span> <span class="toc-text">5.将配置信息同步到所有ceph-node节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%9F%A5%E7%9C%8B%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9%E4%B8%8A%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.5.6.</span> <span class="toc-text">6.查看其他节点上的配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="toc-number">1.5.7.</span> <span class="toc-text">7.查看集群状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E6%96%B0%E5%A2%9E%E5%A4%9A%E4%B8%AAmonitor"><span class="toc-number">1.5.8.</span> <span class="toc-text">8.新增多个monitor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="toc-number">1.5.9.</span> <span class="toc-text">9.查看集群状态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%88%9B%E5%BB%BAceph-mgr"><span class="toc-number">1.6.</span> <span class="toc-text">六、创建ceph mgr</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9C%A8ceph-node1%E8%8A%82%E7%82%B9%E5%88%9B%E5%BB%BAceph-mgr%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.6.1.</span> <span class="toc-text">1.在ceph-node1节点创建ceph mgr服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="toc-number">1.6.2.</span> <span class="toc-text">2.查看集群状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B7%BB%E5%8A%A0%E5%A4%9A%E4%B8%AAceph-mgr"><span class="toc-number">1.6.3.</span> <span class="toc-text">3.添加多个ceph mgr</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="toc-number">1.6.4.</span> <span class="toc-text">4.查看集群状态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E5%88%9B%E5%BB%BAOSD-%E6%95%B0%E6%8D%AE%E7%9B%98"><span class="toc-number">1.7.</span> <span class="toc-text">七、创建OSD(数据盘)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E6%96%B0%E5%A2%9E%E4%BA%86%E7%A1%AC%E7%9B%98"><span class="toc-number">1.7.1.</span> <span class="toc-text">1.检查是否新增了硬盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9D%E5%A7%8B%E5%8C%96%E7%A3%81%E7%9B%98%EF%BC%8C%E6%B8%85%E7%A9%BA%E7%A3%81%E7%9B%98%E6%95%B0%E6%8D%AE"><span class="toc-number">1.7.2.</span> <span class="toc-text">2.初始化磁盘，清空磁盘数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B0%86%E7%A3%81%E7%9B%98%E5%88%9B%E5%BB%BA%E4%B8%BAosd"><span class="toc-number">1.7.3.</span> <span class="toc-text">3.将磁盘创建为osd</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81-1"><span class="toc-number">1.7.4.</span> <span class="toc-text">4.查看集群状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%93%E5%B1%95%EF%BC%9A%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9-%E5%8D%B3%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%8A%82%E7%82%B9"><span class="toc-number">1.7.5.</span> <span class="toc-text">拓展：集群节点扩容(即集群添加新节点)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%90%AF%E7%94%A8ceph-dashboard%E6%8F%92%E4%BB%B6-%E5%8F%AF%E9%80%89%E7%9A%84"><span class="toc-number">1.8.</span> <span class="toc-text">八、启用ceph dashboard插件(可选的)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%A1%AE%E8%AE%A4mgr%E4%B8%BB%E8%8A%82%E7%82%B9"><span class="toc-number">1.8.1.</span> <span class="toc-text">1.确认mgr主节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BC%80%E5%90%AFdashboard%E6%A8%A1%E5%9D%97"><span class="toc-number">1.8.2.</span> <span class="toc-text">2.开启dashboard模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E6%A8%A1%E5%9D%97"><span class="toc-number">1.8.3.</span> <span class="toc-text">3.查看所有模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%88%9B%E5%BB%BA%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6"><span class="toc-number">1.8.4.</span> <span class="toc-text">4.创建自签证书</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%94%9F%E6%88%90dashboard%E9%9C%80%E8%A6%81%E7%9A%84%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6"><span class="toc-number">1.8.5.</span> <span class="toc-text">5.生成dashboard需要的自签证书</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E4%BF%AE%E6%94%B9dashboard%E8%AE%BF%E9%97%AE%E5%9C%B0%E5%9D%80"><span class="toc-number">1.8.6.</span> <span class="toc-text">6.修改dashboard访问地址</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%BF%AE%E6%94%B9dashboard%E7%9B%91%E5%90%AC%E7%AB%AF%E5%8F%A3-%E5%8F%AF%E9%80%89%E7%9A%84"><span class="toc-number">1.8.7.</span> <span class="toc-text">7.修改dashboard监听端口(可选的)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E9%87%8D%E5%90%AFdashboard%E8%AE%A9%E4%BF%AE%E6%94%B9%E7%94%9F%E6%95%88"><span class="toc-number">1.8.8.</span> <span class="toc-text">8.重启dashboard让修改生效</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E6%9F%A5%E7%9C%8Bmgr-service%E7%8A%B6%E6%80%81"><span class="toc-number">1.8.9.</span> <span class="toc-text">9.查看mgr service状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E8%AE%BE%E7%BD%AEdashboard%E6%8F%90%E4%BE%9Bweb%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%81%E7%9A%84%E7%94%A8%E6%88%B7%E5%92%8C%E5%AF%86%E7%A0%81"><span class="toc-number">1.8.10.</span> <span class="toc-text">10.设置dashboard提供web界面认证的用户和密码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95%E8%AE%BF%E9%97%AE"><span class="toc-number">1.8.11.</span> <span class="toc-text">11.浏览器测试访问</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/06/02/132/" title="【容器应用系列教程】容器介绍、Docker的安装和基本操作"><img src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【容器应用系列教程】容器介绍、Docker的安装和基本操作"/></a><div class="content"><a class="title" href="/2023/06/02/132/" title="【容器应用系列教程】容器介绍、Docker的安装和基本操作">【容器应用系列教程】容器介绍、Docker的安装和基本操作</a><time datetime="2023-06-02T02:59:37.570Z" title="发表于 2023-06-02 10:59:37">2023-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/01/131/" title="【虚拟化应用系列教程】OpenStack组件"><img src="/medias/loading.gif" data-original="https://api.ghser.com/random/api.php" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【虚拟化应用系列教程】OpenStack组件"/></a><div class="content"><a class="title" href="/2023/06/01/131/" title="【虚拟化应用系列教程】OpenStack组件">【虚拟化应用系列教程】OpenStack组件</a><time datetime="2023-06-01T09:41:14.757Z" title="发表于 2023-06-01 17:41:14">2023-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/31/130/" title="【虚拟化应用系列教程】KVM存储管理"><img src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【虚拟化应用系列教程】KVM存储管理"/></a><div class="content"><a class="title" href="/2023/05/31/130/" title="【虚拟化应用系列教程】KVM存储管理">【虚拟化应用系列教程】KVM存储管理</a><time datetime="2023-05-31T07:33:09.421Z" title="发表于 2023-05-31 15:33:09">2023-05-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/31/129/" title="【虚拟化应用系列教程】KVM网络管理"><img src="/medias/loading.gif" data-original="https://api.ghser.com/random/api.php" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【虚拟化应用系列教程】KVM网络管理"/></a><div class="content"><a class="title" href="/2023/05/31/129/" title="【虚拟化应用系列教程】KVM网络管理">【虚拟化应用系列教程】KVM网络管理</a><time datetime="2023-05-31T05:20:18.393Z" title="发表于 2023-05-31 13:20:18">2023-05-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/30/128/" title="【虚拟化应用系列教程】KVM虚拟机管理"><img src="/medias/loading.gif" data-original="https://www.dmoe.cc/random.php" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【虚拟化应用系列教程】KVM虚拟机管理"/></a><div class="content"><a class="title" href="/2023/05/30/128/" title="【虚拟化应用系列教程】KVM虚拟机管理">【虚拟化应用系列教程】KVM虚拟机管理</a><time datetime="2023-05-30T10:46:29.825Z" title="发表于 2023-05-30 18:46:29">2023-05-30</time></div></div></div></div></div></div></main><footer id="footer" style="background: flase"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 网笙久久</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=i;var e=n.imageLazyLoadSetting.isSPA,r=(n.imageLazyLoadSetting.preloadRatio,Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));function i(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight+240||document.documentElement.clientHeight+240)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},t.src!==i&&(n.src=i)}()}i(),n.addEventListener("scroll",function(){var t,e;t=i,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body></html>